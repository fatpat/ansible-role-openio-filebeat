#jinja2: lstrip_blocks: True
# {{ ansible_managed }}
---
setup.template.name: "oio-filebeat"
setup.template.pattern: "oio-filebeat"
setup.ilm.enabled: false

filebeat.inputs:
{% for input in openio_filebeat_inputs | list %}

- type: log
  {% for opt, value in openio_filebeat_input_options.items() %}
  {{opt}}: {{value}}
  {% endfor %}
  paths:
    - "{{ input.path }}"
  fields:
    oio_service: "{{ input.service }}"
{% endfor %}

processors:
{% for input in openio_filebeat_inputs | list %}

- dissect:
    tokenizer: "{{ input.format }}"
    field: "message"
    target_prefix: ""
    when.equals:
      oio_service: "{{ input.service }}"
{% endfor %}


# oio_timestamp must exist, otherwise the log line must be discarded
- drop_event:
    when:
      not:
        has_fields: ['oio_timestamp']


# convert oio_timestamp to @timestamp to store actual log event
# and not when the log has been analyzed
- timestamp:
    field: oio_timestamp
    layouts:
      - "2006-01-02T15:04:05.999999Z07:00"
      - "UNIX_MS"

#- convert:
#    fields:
#      - {from: "oio_resp_time", type: "double"}
    
- drop_fields:
    fields: ["message", "beat", "log", "source", "offset", "prospector", "input", "host", "oio_timestamp"]

logging.level: info
logging.to_stdout: true
logging.to_syslog: true
logging.json: false

output.elasticsearch:
  hosts: ["{{ openio_filebeat_elasticsearch_hosts | join('","') }}"]
  protocol: http
  path: /
  index: "oio-filebeat"
  compression_level: 4
  worker: 2
  max_retries: 3
  bulk_max_size: 50
  backoff.init: 1s
  backoff.max: 60s
  timeout: 90
  pipeline: "oio-filebeat"

queue:
  mem:
    events: 4096
    flush.min_events: 2048
    flush.timeout: 1s
...
