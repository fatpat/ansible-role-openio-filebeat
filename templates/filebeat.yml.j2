#jinja2: lstrip_blocks: True
# {{ ansible_managed }}
---
setup.template.name: "oio-filebeat"
setup.template.pattern: "oio-filebeat"
setup.ilm.enabled: false

filebeat.inputs:
{% for input in openio_filebeat_inputs | list %}
- type: log
  {% for opt, value in openio_filebeat_input_options.items() %}
  {{opt}}: {{value}}
  {% endfor %}
  paths:
      - "{{ input.path }}"
  fields:
    oio_service: "{{ input.service }}"
{% endfor %}

processors:
{% for input in openio_filebeat_inputs | list %}
- dissect:
    tokenizer: "{{ input.format }}"
    field: "message"
    target_prefix: ""
    when.equals:
      oio_service: "{{ input.service }}"
{% endfor %}

# convert oio_timestamp to @timestamp to store actual log event
# and not when the log has been analyzed
- timestamp:
    field: oio_timestamp
    layouts:
      - "2006-01-02T15:04:05.999999Z07:00"
    when:
      not:
        equals:
          oio_service: "rawx"

- drop_fields:
    fields: ["message", "beat", "log", "source", "offset", "prospector", "input", "host", "oio_timestamp"]

logging.level: info
logging.to_files: true
logging.files:
  path: {{ openio_filebeat_log_dir }}
  name: filebeat.log
  keepfiles: 7
  permissions: 0644
  rotateeverybytes: 104857600

# TODO: VDO: Support SSL/Configurable options
output.elasticsearch:
  hosts: ["{{ openio_filebeat_elasticsearch_hosts | join('","') }}"]
  protocol: http
  path: /
  index: "oio-filebeat"
  compression_level: 4
  worker: 2
  max_retries: 3
  bulk_max_size: 50
  backoff.init: 1s
  backoff.max: 60s
  timeout: 90
  pipeline: "filebeat"

queue:
  mem:
    events: 4096
    flush.min_events: 2048
    flush.timeout: 1s
...
